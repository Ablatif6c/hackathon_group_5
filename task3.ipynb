{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "The data is from electron microscopy - images of grpahene sheets. The typical image is $(256, 256)$ but we would like to take small patches of this and identify - is there a defect in the patch.\n",
    "\n",
    "Lets go through a few of those things. Below we will look at \n",
    "\n",
    "* A full image\n",
    "* A patch of an image with no defects\n",
    "* A patch with a defect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphene = np.load('full-stack.npy') ## This has 180 different microgrpahs each (256, 256)\n",
    "sample = np.squeeze(graphene[54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "The blue (high electron density) correspnds to atoms and the green correspnds to background.\n",
    "\n",
    "You can see that in the middle of the sheet most of it is a pretty regular array of hexagons, this is what we exepct for the perfect lattice. You will also hopefully see some spots where the hexagon is broken. This many of these are the result of missing atom defects. \n",
    "\n",
    "Notice the edges look a bit weird too. This is standard, and we will generally ignore the edges when analysing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfect patch\n",
    "\n",
    "There is a training dataset of perfect patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.load('./perfect_patches.npy')\n",
    "perfect_sample = pp[0] \n",
    "print(pp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.sum(perfect_sample, axis=0)\n",
    "plt.plot(n1)\n",
    "e1 = np.std(n1)/np.mean(n1)\n",
    "n2 = np.sum(perfect_sample, axis=1)\n",
    "e2 = np.std(n2)/np.mean(n2)\n",
    "plt.plot(n2)\n",
    "e1, e2, np.mean(n1), np.mean(n2), np.std(n1), np.std(n2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(perfect_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defect patch\n",
    "\n",
    "There is also a set of defective patches. Note - these are for testing only, not for training. I guess we could imagine training a classifier on these and the perfect patches - but that would be no fun :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = np.load('./defect_patches.npy')\n",
    "defect_sample = dp[0] \n",
    "print(dp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(defect_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.sum(defect_sample, axis=0)\n",
    "plt.plot(n1)\n",
    "e1 = np.std(n1)/np.mean(n1)\n",
    "n2 = np.sum(defect_sample, axis=1)\n",
    "e2 = np.std(n2)/np.mean(n2)\n",
    "plt.plot(n2)\n",
    "e1, e2, np.mean(n1), np.mean(n2), np.std(n1), np.std(n2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get patches perfect and defect, and put them randomly in a list, with the ground truth saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = np.concatenate([pp, dp])\n",
    "gt = np.concatenate([np.zeros(len(pp)), np.ones(len(dp))])\n",
    "xy = list(zip(patches, gt)) # put labels with data in (data, label) tuple\n",
    "random.shuffle(xy) # shuffle the tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches, gt = list(zip(*xy)) # unzip the tuples to get patches and ground truths as vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "The below fonctions help with the processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(image) -> tuple:\n",
    "    \"\"\"Returns the standard deviations along the x and y axes.\n",
    "\n",
    "    Args:\n",
    "        image (Array): image to compute its standard deviations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (0-axis std, 1-axis std).\n",
    "    \"\"\"\n",
    "    image1 = np.sum(image,axis=1)\n",
    "    image0 = np.sum(image,axis=0)\n",
    "    stdim0 = np.std(image0)\n",
    "    stdim1 = np.std(image1)\n",
    "    return (stdim0,stdim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_horizontally(imgs):\n",
    "    flipped = np.array([cv2.flip(img, 0) for img in imgs])\n",
    "    return flipped\n",
    "\n",
    "def flip_vertically(imgs):\n",
    "    flipped = np.array([cv2.flip(img, 1)  for img in imgs])\n",
    "    return flipped\n",
    "\n",
    "def blur(imgs, kernel = (5,5)):\n",
    "    blurred = np.array([cv2.blur(img, kernel) for img in imgs])\n",
    "    return blurred\n",
    "\n",
    "def augment(defect_imgs):\n",
    "    \"\"\"Augments the dataset by applying a series of transformations.\n",
    "\n",
    "    Args:\n",
    "        defect_imgs (np.array): array of images to augment.\n",
    "\n",
    "    Returns:\n",
    "        np.array: augmented array.\n",
    "    \"\"\"\n",
    "    # Let's first apply some initial transformations.\n",
    "    blurred = blur(defect_imgs)\n",
    "    flip_h = flip_horizontally(defect_imgs)\n",
    "    flip_v = flip_vertically(defect_imgs)\n",
    "    flip_h_v = flip_horizontally(flip_v)\n",
    "    b_h = blur(flip_h)\n",
    "    b_v = blur(flip_v)\n",
    "    b_h_v = blur(flip_h_v)\n",
    "    data = [\n",
    "        defect_imgs,\n",
    "        blurred,\n",
    "        flip_h,\n",
    "        flip_v,\n",
    "        flip_h_v,\n",
    "        b_h,\n",
    "        b_v,\n",
    "        b_h_v,\n",
    "            ]\n",
    "    \n",
    "    # Let's now apply mathematical transformations to the newly \n",
    "    # augmented data set.\n",
    "    cosed = []\n",
    "    sined = []\n",
    "    taned = []\n",
    "    exped = []\n",
    "    \n",
    "    for sub_data in data:\n",
    "        cosed.append(np.cos(sub_data))\n",
    "        sined.append(np.sin(sub_data))\n",
    "        taned.append(np.tan(sub_data))\n",
    "        exped.append(np.exp(sub_data))\n",
    "        \n",
    "    data = np.concatenate((*data, *cosed, *sined, *taned, *exped), axis=0)\n",
    "    data = np.concatenate((data, blur(data, kernel=[7,7])), axis=0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "TODO: Here we augment the defect images to have a 50-50 ratio between the perfect and defect images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 2000\n",
    "X_defect = augment(dp)[:limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting\n",
    "Here we are splitting the data into a:\n",
    "- training data set,\n",
    "- testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect patches\n",
    "X_perfect = pp[:limit]\n",
    "y_perfect = np.zeros(len(X_perfect))\n",
    "X_perfect_train, X_perfect_test, y_perfect_train, y_perfect_test = train_test_split(\n",
    "    X_perfect,\n",
    "    y_perfect,\n",
    "    test_size=0.20,\n",
    "    random_state=42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defect patches\n",
    "y_defect = np.ones(len(X_defect))\n",
    "X_defect_train, X_defect_test, y_defect_train, y_defect_test = train_test_split(\n",
    "    X_defect, \n",
    "    y_defect, \n",
    "    test_size=0.20, \n",
    "    random_state=42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the perfect and defect patches into one training and testing data sets.\n",
    "X_train = np.concatenate((X_perfect_train, X_defect_train), axis = 0)\n",
    "y_train = np.concatenate((y_perfect_train, y_defect_train), axis = 0)\n",
    "print(f\"X_train :\\t {X_train.shape} | y_train :\\t {y_train.shape}\")\n",
    "\n",
    "X_test = np.concatenate((X_perfect_test, X_defect_test), axis = 0)\n",
    "y_test = np.concatenate((y_perfect_test, y_defect_test), axis = 0)\n",
    "print(f\"X_test :\\t {X_test.shape} | y_test :\\t {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppL = []\n",
    "dpL = []\n",
    "for _, img in enumerate(X_perfect_train):\n",
    "    ppL.append(std(img))\n",
    "for _, img in enumerate(X_defect_train):\n",
    "    dpL.append(std(img))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot stds for perfect images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph1 = []\n",
    "ph0 = []\n",
    "for std0, std1 in ppL:\n",
    "    ph1.append(std1)\n",
    "    ph0.append(std0)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].plot(range(len(ppL)), ph0)\n",
    "axes[1].plot(range(len(ppL)), ph1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh1 = []\n",
    "dh0 = []\n",
    "for std0, std1 in dpL:\n",
    "    dh1.append(std1)\n",
    "    dh0.append(std0)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].plot(range(len(dpL)), dh0)\n",
    "axes[1].plot(range(len(dpL)), dh1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformt the input training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattens= []\n",
    "for input in X_train:\n",
    "    stds = std(input)\n",
    "    flattened = np.ndarray.flatten(input)\n",
    "    flattened = np.append(flattened, stds)\n",
    "    \n",
    "    flattens.append(flattened)\n",
    "\n",
    "flattens = np.array(flattens)\n",
    "print(flattens.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nnCSD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b70407b734528e7f3c3848197deb6f1f9463d74c30cf7c3b392502c330d5d9d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
